"""
Utility for loading a model.
"""
from argparse import Namespace
from copy import deepcopy
import os
import pickle as pkl
from typing import Optional

import numpy as np
from pytorch_lightning import Trainer

from dynamics_toolbox.models.abstract_dynamics_model import\
        AbstractDynamicsModel
from dynamics_toolbox.models.pl_models import PL_MODELS
from dynamics_toolbox.models.pl_models.pl_ensemble import FinitePlEnsemble

def load_model(
        run_id: str,
        version: Optional[int] = None,
        epoch: Optional[int] = None,
        default_root: str = 'trained_models',
) -> AbstractDynamicsModel:
    """
    Load in a model.
    Args:
        run_id: The run_id of the model to load.
        path: The path to the model to load in.
        version: The version number to load in. If not specified, load the
            the latest version.
        epoch: Epoch of the checkpoint to load in. If not specified, load the
            last checkpoint recorded.
        default_root: The root directory to models.
    Returns:
        The loaded dynamics model.
    """
    path = os.path.join(default_root, run_id)
    path = os.path.join(path, 'lightning_logs')
    version_dirs = os.listdir(path)
    versions = [int(v.split('_')[1]) for v in version_dirs]
    if version is not None:
        if version not in versions:
            raise ValueError(f'Did not find version {version}')
        path = os.path.join(path, f'version_{version}')
    else:
        path = os.path.join(path, f'version_{max(versions)}')
    with open(os.path.join(path, 'config.pkl'), 'rb') as f:
        args = Namespace(**pkl.load(f))
    path = os.path.join(path, 'checkpoints')
    checkpoints = os.listdir(path)
    epochs = [int(ck.split('-')[0].split('=')[1]) for ck in checkpoints]
    if epoch is not None:
        if epoch not in epochs:
            raise ValueError(f'Did not find epoch {epoch} in checkpoints.')
        epidx = epochs.index(epoch)
    else:
        epidx = np.argmax(epochs)
    path = os.path.join(path, checkpoints[epidx])
    if args.num_ensemble_members > 1:
        return FinitePlEnsemble.load_from_checkpoint(path, member_config=args)
    else:
        return PL_MODELS[args.model_type].load_from_checkpoint(path)

def save_config(trainer: Trainer, args: Namespace) -> None:
    """
    Save a Namespace config to the appropriate place.
    Args:
        trainer: The trainer generated by the config.
        args: The arguments to save.
    """
    version_path = os.path.join(deepcopy(trainer.default_root_dir),
        f'lightning_logs/version_{trainer.logger.version}')
    if not os.path.exists(version_path):
        os.makedirs(version_path)
    with open(os.path.join(version_path, 'config.pkl'), 'wb') as f:
        pkl.dump(vars(args), f)

